<?xml version="1.0" encoding="UTF-8"?>
<!--
~ Copyright The WildFly Authors
~ SPDX-License-Identifier: Apache-2.0
-->
<layer-spec xmlns="urn:jboss:galleon:layer-spec:2.0" name="in-memory-embedding-model-all-minilm-l6-v2-q">
    <props>
        <prop name="org.wildfly.category" value="AI"/>
        <prop name="org.wildfly.description" value="Support for a quantized sentenceTransformers all-MiniLM-L6-v2 embedding model that runs within your Java application's process."/>
        <prop name="org.wildfly.stability" value="experimental"/>
        <prop name="org.wildfly.rule.add-on-depends-on" value="only:ai"/>
        <prop name="org.wildfly.rule.add-on" value="ai-embedding-model,in-memory-embedding-model-all-minilm-l6-v2-q"/>
        <prop name="org.wildfly.rule.add-on-description" value="Quantized SentenceTransformers all-MiniLM-L6-v2 embedding model that runs within your Java application's process."/>
    </props>
    <dependencies>
        <layer name="ai"/>
    </dependencies>
    <packages>
        <package name="dev.langchain4j.embeddings.all-minilm-l6-v2-q"/>
    </packages>
    <feature spec="subsystem.ai">
        <feature spec="subsystem.ai.in-memory-embedding-model">
            <param name="in-memory-embedding-model" value="all-minilm-l6-v2-q"/>
            <param name="module" value="dev.langchain4j.embeddings.all-minilm-l6-v2-q"/>
            <param name="embedding-class" value="dev.langchain4j.model.embedding.onnx.allminilml6v2q.AllMiniLmL6V2QuantizedEmbeddingModel"/>
        </feature>
    </feature>
</layer-spec>
